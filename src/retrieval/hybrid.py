#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ··åˆæ£€ç´¢å¼•æ“ - Hybrid Retrieval Engine
ç»“åˆå‘é‡æ£€ç´¢ï¼ˆChromaDBï¼‰å’Œå…³é”®è¯æ£€ç´¢ï¼ˆBM25ï¼‰
"""

import chromadb
from FlagEmbedding import BGEM3FlagModel
from rank_bm25 import BM25Okapi
import jieba
from typing import List, Dict
import numpy as np
import threading
from collections import OrderedDict
from concurrent.futures import ThreadPoolExecutor


class VectorRetriever:
    """å‘é‡æ£€ç´¢å™¨ - åŸºäº ChromaDB + BGE-M3"""

    _model = None
    _model_lock = threading.Lock()
    _embedding_cache = OrderedDict()
    _embedding_cache_lock = threading.Lock()
    _embedding_cache_size = 256
    
    def __init__(self, chroma_path: str = "./chroma_db", collection_name: str = "diabetes_guidelines_2024"):
        """
        åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨
        
        Args:
            chroma_path: ChromaDB å­˜å‚¨è·¯å¾„
            collection_name: é›†åˆåç§°
        """
        print("ğŸ”§ åˆå§‹åŒ–å‘é‡æ£€ç´¢å™¨...")
        with VectorRetriever._model_lock:
            if VectorRetriever._model is None:
                VectorRetriever._model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=True)
        self.model = VectorRetriever._model
        self.client = chromadb.PersistentClient(path=chroma_path)
        self.collection = self.client.get_collection(name=collection_name)
        print("âœ… å‘é‡æ£€ç´¢å™¨å°±ç»ª")

    def _encode_query(self, query: str):
        with VectorRetriever._embedding_cache_lock:
            cached = VectorRetriever._embedding_cache.get(query)
            if cached is not None:
                VectorRetriever._embedding_cache.move_to_end(query)
                return cached

        query_embedding = self.model.encode([query])['dense_vecs'][0]

        with VectorRetriever._embedding_cache_lock:
            VectorRetriever._embedding_cache[query] = query_embedding
            VectorRetriever._embedding_cache.move_to_end(query)
            if len(VectorRetriever._embedding_cache) > VectorRetriever._embedding_cache_size:
                VectorRetriever._embedding_cache.popitem(last=False)

        return query_embedding
    
    def retrieve(self, query: str, top_k: int = 10) -> List[Dict]:
        """
        å‘é‡æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            List of {id, document, metadata, score}
        """
        # æŸ¥è¯¢å‘é‡åŒ–ï¼ˆå¸¦ç¼“å­˜ï¼‰
        query_embedding = self._encode_query(query)
        
        # æ£€ç´¢
        results = self.collection.query(
            query_embeddings=[query_embedding.tolist()],
            n_results=top_k
        )
        
        # æ ¼å¼åŒ–ç»“æœ
        retrieved = []
        for i in range(len(results['ids'][0])):
            retrieved.append({
                'id': results['ids'][0][i],
                'document': results['documents'][0][i],
                'metadata': results['metadatas'][0][i],
                'score': 1 - results['distances'][0][i],  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                'source': 'vector'
            })
        
        return retrieved


class KeywordRetriever:
    """å…³é”®è¯æ£€ç´¢å™¨ - åŸºäº BM25"""

    _index_cache = {}
    _index_lock = threading.Lock()
    
    def __init__(self, chroma_path: str = "./chroma_db", collection_name: str = "diabetes_guidelines_2024"):
        """
        åˆå§‹åŒ–å…³é”®è¯æ£€ç´¢å™¨
        
        Args:
            chroma_path: ChromaDB å­˜å‚¨è·¯å¾„ï¼ˆç”¨äºåŠ è½½æ–‡æ¡£ï¼‰
            collection_name: é›†åˆåç§°
        """
        print("ğŸ”§ åˆå§‹åŒ–å…³é”®è¯æ£€ç´¢å™¨...")

        cache_key = (chroma_path, collection_name)
        cached = None
        with KeywordRetriever._index_lock:
            cached = KeywordRetriever._index_cache.get(cache_key)

        if cached is None:
            # ä» ChromaDB åŠ è½½æ‰€æœ‰æ–‡æ¡£
            client = chromadb.PersistentClient(path=chroma_path)
            collection = client.get_collection(name=collection_name)

            # è·å–æ‰€æœ‰æ–‡æ¡£
            all_data = collection.get()
            documents = all_data['documents']
            ids = all_data['ids']
            metadatas = all_data['metadatas']

            # åˆ†è¯å¹¶å»ºç«‹BM25ç´¢å¼•
            print(f"ğŸ“„ å¯¹ {len(documents)} ç¯‡æ–‡æ¡£åˆ†è¯...")
            tokenized_corpus = [list(jieba.cut(doc)) for doc in documents]
            bm25 = BM25Okapi(tokenized_corpus)

            with KeywordRetriever._index_lock:
                if cache_key not in KeywordRetriever._index_cache:
                    KeywordRetriever._index_cache[cache_key] = (documents, ids, metadatas, bm25)
                cached = KeywordRetriever._index_cache[cache_key]

        self.documents, self.ids, self.metadatas, self.bm25 = cached
        print("âœ… å…³é”®è¯æ£€ç´¢å™¨å°±ç»ª")
    
    def retrieve(self, query: str, top_k: int = 10) -> List[Dict]:
        """
        BM25 å…³é”®è¯æ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
        
        Returns:
            List of {id, document, metadata, score}
        """
        # æŸ¥è¯¢åˆ†è¯
        tokenized_query = list(jieba.cut(query))
        
        # BM25 æ‰“åˆ†
        scores = self.bm25.get_scores(tokenized_query)
        
        # è·å– Top-K
        top_indices = np.argsort(scores)[::-1][:top_k]
        
        # æ ¼å¼åŒ–ç»“æœ
        retrieved = []
        for idx in top_indices:
            if scores[idx] > 0:  # è¿‡æ»¤é›¶åˆ†ç»“æœ
                retrieved.append({
                    'id': self.ids[idx],
                    'document': self.documents[idx],
                    'metadata': self.metadatas[idx],
                    'score': float(scores[idx]),
                    'source': 'keyword'
                })
        
        return retrieved


class HybridRetriever:
    """æ··åˆæ£€ç´¢å™¨ - èåˆå‘é‡æ£€ç´¢å’Œå…³é”®è¯æ£€ç´¢"""
    
    def __init__(self, chroma_path: str = "./chroma_db", collection_name: str = "diabetes_guidelines_2024"):
        """
        åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
        
        Args:
            chroma_path: ChromaDB å­˜å‚¨è·¯å¾„
            collection_name: é›†åˆåç§°
        """
        self.vector_retriever = VectorRetriever(chroma_path, collection_name)
        self.keyword_retriever = KeywordRetriever(chroma_path, collection_name)
    
    def reciprocal_rank_fusion(self, 
                                vector_results: List[Dict], 
                                keyword_results: List[Dict], 
                                k: int = 60) -> List[Dict]:
        """
        Reciprocal Rank Fusion (RRF) ç®—æ³•èåˆç»“æœ
        
        å…¬å¼: RRF_score(d) = Î£ 1/(k + rank_i(d))
        
        Args:
            vector_results: å‘é‡æ£€ç´¢ç»“æœ
            keyword_results: å…³é”®è¯æ£€ç´¢ç»“æœ
            k: RRF å‚æ•°ï¼ˆé»˜è®¤60ï¼‰
        
        Returns:
            èåˆåçš„ç»“æœåˆ—è¡¨
        """
        # æ„å»ºæ’åå­—å…¸
        rrf_scores = {}
        
        # å‘é‡æ£€ç´¢æ’å
        for rank, item in enumerate(vector_results, start=1):
            doc_id = item['id']
            if doc_id not in rrf_scores:
                rrf_scores[doc_id] = {
                    'score': 0,
                    'document': item['document'],
                    'metadata': item['metadata'],
                    'sources': []
                }
            rrf_scores[doc_id]['score'] += 1 / (k + rank)
            rrf_scores[doc_id]['sources'].append('vector')
        
        # å…³é”®è¯æ£€ç´¢æ’å
        for rank, item in enumerate(keyword_results, start=1):
            doc_id = item['id']
            if doc_id not in rrf_scores:
                rrf_scores[doc_id] = {
                    'score': 0,
                    'document': item['document'],
                    'metadata': item['metadata'],
                    'sources': []
                }
            rrf_scores[doc_id]['score'] += 1 / (k + rank)
            rrf_scores[doc_id]['sources'].append('keyword')
        
        # æ’åº
        fused_results = [
            {
                'id': doc_id,
                'document': data['document'],
                'metadata': data['metadata'],
                'rrf_score': data['score'],
                'sources': data['sources']
            }
            for doc_id, data in rrf_scores.items()
        ]
        fused_results.sort(key=lambda x: x['rrf_score'], reverse=True)
        
        return fused_results
    
    def retrieve(self, query: str, top_k: int = 10) -> List[Dict]:
        """
        æ··åˆæ£€ç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: åˆç­›æ•°é‡ï¼ˆæ¯ä¸ªæ£€ç´¢å™¨ï¼‰
        
        Returns:
            èåˆåçš„æ£€ç´¢ç»“æœ
        """
        print(f"\nğŸ” æ··åˆæ£€ç´¢: {query}")

        # å¹¶è¡Œæ£€ç´¢
        print("  ğŸ“Š å‘é‡æ£€ç´¢ + ğŸ“ å…³é”®è¯æ£€ç´¢ å¹¶å‘æ‰§è¡Œ...")
        with ThreadPoolExecutor(max_workers=2) as executor:
            vector_future = executor.submit(self.vector_retriever.retrieve, query, top_k)
            keyword_future = executor.submit(self.keyword_retriever.retrieve, query, top_k)
            vector_results = vector_future.result()
            keyword_results = keyword_future.result()
        
        # RRF èåˆ
        print("  ğŸ”€ èåˆç»“æœä¸­...")
        fused_results = self.reciprocal_rank_fusion(vector_results, keyword_results)
        
        print(f"  âœ… è¿”å› {len(fused_results)} æ¡ç»“æœ")
        return fused_results


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # åˆå§‹åŒ–
    retriever = HybridRetriever()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "eGFRå°äº30çš„æ‚£è€…ä¸èƒ½ä½¿ç”¨å“ªäº›è¯ç‰©ï¼Ÿ",
        "ç³–å°¿ç—…æ‚£è€…çš„è¿åŠ¨å»ºè®®æ˜¯ä»€ä¹ˆï¼Ÿ",
        "SGLT2æŠ‘åˆ¶å‰‚çš„ç¦å¿Œç—‡æœ‰å“ªäº›ï¼Ÿ"
    ]
    
    for query in test_queries:
        results = retriever.retrieve(query, top_k=5)
        
        print(f"\n{'='*60}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*60}")
        
        for i, result in enumerate(results[:3], 1):
            print(f"\n[{i}] RRFåˆ†æ•°: {result['rrf_score']:.4f}")
            print(f"æ¥æº: {', '.join(result['sources'])}")
            print(f"ç« èŠ‚: {result['metadata'].get('header', 'N/A')}")
            print(f"å†…å®¹: {result['document'][:150]}...")
