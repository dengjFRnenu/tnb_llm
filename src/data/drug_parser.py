#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Markdownè§£æå™¨ - å°†data.mdè§£æä¸ºç»“æ„åŒ–JSON

åŠŸèƒ½:
1. åˆ†å‰²120ä¸ªè¯å“æ¡ç›®
2. æå–åŸºç¡€ä¿¡æ¯(é€šç”¨åã€å•†å“åã€è‹±æ–‡å)
3. æå–ä¸´åºŠä¿¡æ¯(é€‚åº”ç—‡ã€ç¦å¿Œã€ç”¨æ³•ç”¨é‡ç­‰)
4. è¾“å‡ºä¸ºJSONæ ¼å¼
"""

import re
import json
from dataclasses import dataclass, asdict, field
from typing import Optional, List
from pathlib import Path


@dataclass
class Drug:
    """è¯å“æ•°æ®ç»“æ„"""
    id: str
    name: str  # é€šç”¨å
    en_name: str  # è‹±æ–‡å
    brand_names: List[str]  # å•†å“ååˆ—è¡¨
    ingredients: str  # æˆä»½
    indications: str  # é€‚åº”ç—‡
    dosage: str  # ç”¨æ³•ç”¨é‡
    adverse_reactions: str  # ä¸è‰¯ååº”
    contraindications: str  # ç¦å¿Œ
    precautions: str  # æ³¨æ„äº‹é¡¹
    pharmacology: str = ""  # è¯ç†æ¯’ç†(å¯é€‰)
    interactions: str = ""  # è¯ç‰©ç›¸äº’ä½œç”¨(å¯é€‰)
    raw_text: str = field(repr=False, default="")  # åŸå§‹æ–‡æœ¬(ç”¨äºè°ƒè¯•)


def extract_field(pattern: str, text: str, default: str = "") -> str:
    """é€šç”¨å­—æ®µæå–å‡½æ•°"""
    match = re.search(pattern, text, re.DOTALL)
    return match.group(1).strip() if match else default


def extract_brands(text: str) -> List[str]:
    """æå–å•†å“å,å¤„ç†å¤šä¸ªå•†å“åçš„æƒ…å†µ"""
    match = re.search(r'å•†å“åç§°[:ï¼š]\s*(.+?)(?:\n|$)', text)
    if not match:
        return []
    
    brand_text = match.group(1).strip()
    # å¤„ç† "æ ¼åæ­¢ / å¡å¸å¹³" æˆ– "æ ¼åæ­¢"
    brands = [b.strip() for b in re.split(r'[/ï¼]', brand_text)]
    return [b for b in brands if b]  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²


def extract_section_content(section_title: str, text: str) -> str:
    """
    æå–ç« èŠ‚å†…å®¹
    åŒ¹é…: **ã€ç« èŠ‚åã€‘** åçš„å†…å®¹,ç›´åˆ°ä¸‹ä¸€ä¸ª **ã€ æˆ– --- æˆ–æ–‡æœ¬ç»“æŸ
    """
    # å¤„ç†ä¸­è‹±æ–‡æ ‡ç‚¹
    title_pattern = section_title.replace('ã€', r'[ã€\[]').replace('ã€‘', r'[ã€‘\]]')
    pattern = rf'\*\*{title_pattern}\*\*\s*(.*?)(?=\*\*[ã€\[]|---|$)'
    
    match = re.search(pattern, text, re.DOTALL)
    if match:
        content = match.group(1).strip()
        # æ¸…ç†å¤šä½™çš„ç©ºè¡Œ
        content = re.sub(r'\n{3,}', '\n\n', content)
        return content
    return ""


def split_into_drugs(content: str) -> List[str]:
    """
    å°†æ•´ä¸ªæ–‡ä»¶æŒ‰è¯å“æ¡ç›®åˆ†å‰²
    åŒ¹é…: ### ç¬¬ X ä¸ªï¼šè¯å“å
    """
    # åˆ†å‰²æ ‡è®°
    pattern = r'###\s*ç¬¬\s*\d+\s*ä¸ª[ï¼š:]'
    
    # æ‰¾åˆ°æ‰€æœ‰åˆ†å‰²ç‚¹
    splits = list(re.finditer(pattern, content))
    
    drug_texts = []
    for i, match in enumerate(splits):
        start = match.start()
        # ä¸‹ä¸€ä¸ªè¯å“çš„å¼€å§‹ä½ç½®,æˆ–æ–‡æœ¬ç»“æŸ
        end = splits[i + 1].start() if i + 1 < len(splits) else len(content)
        drug_texts.append(content[start:end])
    
    return drug_texts


def parse_drug_entry(text: str, index: int) -> Drug:
    """
    è§£æå•ä¸ªè¯å“æ¡ç›®
    
    Args:
        text: è¯å“çš„åŸå§‹markdownæ–‡æœ¬
        index: åºå·(ç”¨äºID)
    
    Returns:
        Drugå¯¹è±¡
    """
    # æå–æ ‡é¢˜ä¸­çš„IDå’Œåç§°
    title_match = re.search(r'###\s*ç¬¬\s*(\d+)\s*ä¸ª[ï¼š:]\s*(.+?)\s*\((.+?)\)', text)
    
    if title_match:
        drug_id = title_match.group(1)
        zh_name = title_match.group(2).strip()
        en_name = title_match.group(3).strip()
    else:
        # å¤‡ç”¨æ–¹æ¡ˆ:å¦‚æœæ ¼å¼ä¸æ ‡å‡†
        drug_id = str(index + 1)
        zh_name = f"è¯å“{drug_id}"
        en_name = ""
    
    # æå–åŸºç¡€ä¿¡æ¯
    name_section = extract_section_content('ã€è¯å“åç§°ã€‘', text)
    é€šç”¨å = extract_field(r'é€šç”¨åç§°[:ï¼š]\s*(.+?)(?:\n|$)', name_section, zh_name)
    è‹±æ–‡å = extract_field(r'è‹±æ–‡åç§°[:ï¼š]\s*(.+?)(?:\n|$)', name_section, en_name)
    
    # æå–å•†å“å
    brands = extract_brands(name_section)
    
    # æå–å„ä¸ªä¸´åºŠä¿¡æ¯ç« èŠ‚
    æˆä»½ = extract_section_content('ã€æˆä»½ã€‘', text)
    é€‚åº”ç—‡ = extract_section_content('ã€é€‚åº”ç—‡ã€‘', text)
    ç”¨æ³•ç”¨é‡ = extract_section_content('ã€ç”¨æ³•ç”¨é‡ã€‘', text)
    ä¸è‰¯ååº” = extract_section_content('ã€ä¸è‰¯ååº”ã€‘', text)
    ç¦å¿Œ = extract_section_content('ã€ç¦å¿Œã€‘', text)
    æ³¨æ„äº‹é¡¹ = extract_section_content('ã€æ³¨æ„äº‹é¡¹ã€‘', text)
    è¯ç†æ¯’ç† = extract_section_content('ã€è¯ç†æ¯’ç†ã€‘|ã€è¯ç†ä½œç”¨ã€‘', text)
    è¯ç‰©ç›¸äº’ä½œç”¨ = extract_section_content('ã€è¯ç‰©ç›¸äº’ä½œç”¨ã€‘', text)
    
    return Drug(
        id=drug_id,
        name=é€šç”¨å,
        en_name=è‹±æ–‡å,
        brand_names=brands,
        ingredients=æˆä»½,
        indications=é€‚åº”ç—‡,
        dosage=ç”¨æ³•ç”¨é‡,
        adverse_reactions=ä¸è‰¯ååº”,
        contraindications=ç¦å¿Œ,
        precautions=æ³¨æ„äº‹é¡¹,
        pharmacology=è¯ç†æ¯’ç†,
        interactions=è¯ç‰©ç›¸äº’ä½œç”¨,
        raw_text=text[:500]  # ä¿ç•™å‰500å­—ç¬¦ç”¨äºè°ƒè¯•
    )


def parse_all_drugs(filepath: str) -> List[Drug]:
    """
    è§£ææ•´ä¸ªdata.mdæ–‡ä»¶
    
    Args:
        filepath: data.mdçš„è·¯å¾„
    
    Returns:
        Drugå¯¹è±¡åˆ—è¡¨
    """
    print(f"ğŸ“– æ­£åœ¨è¯»å–æ–‡ä»¶: {filepath}")
    
    with open(filepath, 'r', encoding='utf-8') as f:
        content = f.read()
    
    print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
    
    # åˆ†å‰²è¯å“æ¡ç›®
    drug_texts = split_into_drugs(content)
    print(f"âœ‚ï¸  æ‰¾åˆ° {len(drug_texts)} ä¸ªè¯å“æ¡ç›®")
    
    # è§£ææ¯ä¸ªè¯å“
    drugs = []
    for i, text in enumerate(drug_texts):
        try:
            drug = parse_drug_entry(text, i)
            drugs.append(drug)
            print(f"âœ… [{i+1}/{len(drug_texts)}] {drug.name}")
        except Exception as e:
            print(f"âŒ [{i+1}/{len(drug_texts)}] è§£æå¤±è´¥: {e}")
            continue
    
    print(f"\nğŸ‰ æˆåŠŸè§£æ {len(drugs)} ä¸ªè¯å“!")
    return drugs


def save_to_json(drugs: List[Drug], output_path: str):
    """ä¿å­˜ä¸ºJSONæ–‡ä»¶"""
    data = [asdict(drug) for drug in drugs]
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_path}")
    print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {Path(output_path).stat().st_size / 1024:.1f} KB")


def main():
    """ä¸»å‡½æ•°"""
    # è¾“å…¥è¾“å‡ºè·¯å¾„
    input_file = "data.md"
    output_file = "drugs_structured.json"
    
    print("=" * 60)
    print("ğŸ¥ ç³–å°¿ç—…è¯å“æ•°æ®è§£æå™¨")
    print("=" * 60)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(input_file).exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {input_file}")
        return
    
    # è§£ææ‰€æœ‰è¯å“
    drugs = parse_all_drugs(input_file)
    
    if not drugs:
        print("âŒ é”™è¯¯: æ²¡æœ‰æˆåŠŸè§£æä»»ä½•è¯å“")
        return
    
    # ä¿å­˜ä¸ºJSON
    save_to_json(drugs, output_file)
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ•°æ®ç»Ÿè®¡")
    print("=" * 60)
    print(f"æ€»è¯å“æ•°: {len(drugs)}")
    print(f"æœ‰å•†å“åçš„: {sum(1 for d in drugs if d.brand_names)}")
    print(f"æœ‰è‹±æ–‡åçš„: {sum(1 for d in drugs if d.en_name)}")
    print(f"æœ‰ç¦å¿Œä¿¡æ¯çš„: {sum(1 for d in drugs if d.contraindications)}")
    print(f"æœ‰ç”¨æ³•ç”¨é‡çš„: {sum(1 for d in drugs if d.dosage)}")
    
    # æ˜¾ç¤ºå‰3ä¸ªè¯å“ç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ğŸ“‹ å‰3ä¸ªè¯å“ç¤ºä¾‹")
    print("=" * 60)
    for drug in drugs[:3]:
        print(f"\n{drug.id}. {drug.name}")
        print(f"   è‹±æ–‡å: {drug.en_name}")
        print(f"   å•†å“å: {', '.join(drug.brand_names) if drug.brand_names else 'æ— '}")
        print(f"   ç¦å¿Œé•¿åº¦: {len(drug.contraindications)} å­—ç¬¦")


if __name__ == "__main__":
    main()
