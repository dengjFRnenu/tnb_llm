#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®ä½“æå–å™¨ - ä»ç»“æ„åŒ–è¯å“æ•°æ®ä¸­æå–å›¾è°±å®ä½“å’Œå…³ç³»

åŠŸèƒ½:
1. æ¨æ–­è¯ç‰©åˆ†ç±»(Category)
2. æå–ç–¾ç—…å®ä½“(Disease)ä»é€‚åº”ç—‡å’Œç¦å¿Œ
3. æå–Metricçº¦æŸ(eGFR < 30ç­‰)
4. æ„å»ºå…³ç³»æ•°æ®
5. è¾“å‡ºä¸ºNeo4jå‹å¥½çš„JSONæ ¼å¼
"""

import re
import json
from typing import List, Dict, Set, Tuple
from collections import defaultdict


class EntityExtractor:
    """å®ä½“å’Œå…³ç³»æå–å™¨"""
    
    def __init__(self):
        # è¯ç‰©åˆ†ç±»è§„åˆ™
        self.category_rules = {
            'åŒèƒç±»': [r'äºŒç”²åŒèƒ', r'è‹¯ä¹™åŒèƒ'],
            'ç£ºè„²ç±»': [r'æ ¼åˆ—\w+', r'ä¼˜é™ç³–'],
            'DPP-4æŠ‘åˆ¶å‰‚': [r'(è¥¿|æ²™|åˆ©|ç»´|é˜¿)æ ¼åˆ—æ±€', r'DPP-4'],
            'SGLT2æŠ‘åˆ¶å‰‚': [r'(è¾¾|æ©|å¡|åŸƒ|æ’)æ ¼åˆ—å‡€', r'SGLT'],
            'TZDç±»': [r'å¡æ ¼åˆ—é…®', r'ç½—æ ¼åˆ—é…®', r'å™»å”‘çƒ·äºŒé…®'],
            'GLP-1æ¿€åŠ¨å‰‚': [r'(åˆ©æ‹‰|å¸ç¾|åº¦æ‹‰|æ´›å¡é‚£|åˆ©å¸é‚£|è‰¾å¡é‚£|è´é‚£|é˜¿å¿…)è‚½', r'GLP-1'],
            'Î±-ç³–è‹·é…¶æŠ‘åˆ¶å‰‚': [r'é˜¿å¡æ³¢ç³–', r'ä¼æ ¼åˆ—æ³¢ç³–', r'ç±³æ ¼åˆ—é†‡'],
            'æ ¼åˆ—å¥ˆç±»': [r'(ç‘|é‚£|ç±³)æ ¼åˆ—å¥ˆ', r'æ ¼åˆ—å¥ˆ'],
            'èƒ°å²›ç´ ': [r'èƒ°å²›ç´ ', r'insulin'],
            'èƒ†æ±é…¸è¯åˆå‰‚': [r'è€ƒæ¥\w+'],
            'å…¶ä»–': [r'æº´éšäº­', r'æ™®å…°æ—è‚½', r'æ°¯åŒ–é“¬', r'å¡å•¶ç”²é…¸é“¬'],
        }
        
        # ç–¾ç—…å®ä½“æ¨¡å¼
        self.disease_patterns = [
            # ç³–å°¿ç—…ç›¸å…³
            r'[12]\s*å‹ç³–å°¿ç—…',
            r'ç³–å°¿ç—…',
            r'é«˜è¡€ç³–',
            r'é…®ç—‡é…¸ä¸­æ¯’',
            r'ç³–å°¿ç—…\w*å¹¶å‘ç—‡',
            
            # å¿ƒè¡€ç®¡ç–¾ç—…
            r'å¿ƒåŠ›è¡°ç«­', r'å¿ƒè¡°', r'å……è¡€æ€§å¿ƒåŠ›è¡°ç«­',
            r'å¿ƒè‚Œæ¢—æ­»', r'å¿ƒè‚Œæ¢—å¡',
            r'å¿ƒè¡€ç®¡ç–¾ç—…',
            r'å¿ƒç»ç—›',
            r'å† å¿ƒç—…',
            
            # è‚¾è„ç–¾ç—…
            r'è‚¾åŠŸèƒ½ä¸å…¨', r'è‚¾åŠŸèƒ½æŸå®³', r'è‚¾åŠŸèƒ½å—æŸ',
            r'æ…¢æ€§è‚¾\w*ç—…', r'CKD',
            r'è‚¾è¡°ç«­', r'ç»ˆæœ«æœŸè‚¾ç—…',
            r'è‚¾ç—…ç»¼åˆå¾',
            
            # è‚è„ç–¾ç—…
            r'è‚åŠŸèƒ½ä¸å…¨', r'è‚åŠŸèƒ½æŸå®³',
            r'è‚è¡°ç«­',
            r'çˆ†å‘æ€§è‚ç‚',
            r'é»„ç–¸',
            
            # å…¶ä»–ä»£è°¢ç–¾ç—…
            r'ä½è¡€ç³–',
            r'ä¹³é…¸é…¸ä¸­æ¯’',
            r'ä»£è°¢æ€§é…¸ä¸­æ¯’',
            
            # ç™Œç—‡
            r'è†€èƒ±ç™Œ',
            r'ç”²çŠ¶è…ºé«“æ ·ç™Œ', r'MTC',
            r'èƒ°è…ºç™Œ',
            
            # å…¶ä»–
            r'èƒ°è…ºç‚',
            r'é…’ç²¾ä¸­æ¯’', r'é…—é…’',
            r'ä¼‘å…‹',
            r'æ„ŸæŸ“',
            r'å‘¼å¸è¡°ç«­',
        ]
        
        # Metricæ¨¡å¼
        self.metric_patterns = {
            'eGFR': [
                r'eGFR\s*([<>â‰¥â‰¤])\s*(\d+)\s*(mL/min)?',
                r'eGFR\s*(\d+)-(\d+)',  # èŒƒå›´
            ],
            'CrCl': [
                r'(è‚Œé…æ¸…é™¤ç‡|CrCl)\s*([<>â‰¥â‰¤])\s*(\d+)',
            ],
            'ALT': [
                r'(ALT|è½¬æ°¨é…¶|ä¸™æ°¨é…¸æ°¨åŸºè½¬ç§»é…¶)\s*>\s*(\d+)\s*å€',
                r'(ALT|AST)\s*>\s*æ­£å¸¸ä¸Šé™\s*(\d+)\s*å€',
            ],
            'BMI': [
                r'BMI\s*([<>â‰¥â‰¤])\s*(\d+)',
            ],
            'ç”˜æ²¹ä¸‰é…¯': [
                r'ç”˜æ²¹ä¸‰é…¯\s*>\s*(\d+)\s*mg/dL',
            ],
        }
    
    def infer_category(self, drug: Dict) -> str:
        """æ¨æ–­è¯ç‰©åˆ†ç±»"""
        text = f"{drug['name']} {drug.get('ingredients', '')} {drug.get('pharmacology', '')}"
        
        for category, patterns in self.category_rules.items():
            for pattern in patterns:
                if re.search(pattern, text, re.IGNORECASE):
                    return category
        
        return 'æœªåˆ†ç±»'
    
    def extract_diseases(self, text: str, source_type: str) -> List[Dict]:
        """
        ä»æ–‡æœ¬ä¸­æå–ç–¾ç—…å®ä½“
        
        Args:
            text: è¦æå–çš„æ–‡æœ¬
            source_type: æ¥æºç±»å‹('é€‚åº”ç—‡'æˆ–'ç¦å¿Œ')
        
        Returns:
            ç–¾ç—…å®ä½“åˆ—è¡¨
        """
        diseases = []
        seen = set()
        
        for pattern in self.disease_patterns:
            for match in re.finditer(pattern, text, re.IGNORECASE):
                disease_name = match.group(0)
                # è§„èŒƒåŒ–åç§°
                disease_name = disease_name.replace(' ', '')
                
                if disease_name not in seen:
                    diseases.append({
                        'name': disease_name,
                        'type': source_type,
                        'context': text[max(0, match.start()-20):match.end()+20]
                    })
                    seen.add(disease_name)
        
        return diseases
    
    def extract_metric_constraints(self, text: str) -> List[Dict]:
        """
        æå–Metricçº¦æŸ
        
        Returns:
            çº¦æŸåˆ—è¡¨,æ¯ä¸ªåŒ…å«: metric, operator, value, unitç­‰
        """
        constraints = []
        
        # eGFRæå–
        # 1. ç®€å•æ¯”è¾ƒ: eGFR < 30
        for match in re.finditer(r'eGFR\s*([<>â‰¥â‰¤ï¼œï¼])\s*(\d+)\s*(mL/min)?', text):
            operator = match.group(1).replace('ï¼œ', '<').replace('ï¼', '>')
            value = float(match.group(2))
            
            constraints.append({
                'metric': 'eGFR',
                'operator': operator,
                'value': value,
                'unit': 'mL/min',
                'severity': 'CRITICAL' if operator in ['<', 'â‰¤'] and value == 30 else 'WARNING',
                'context': match.group(0)
            })
        
        # 2. èŒƒå›´: eGFR 30-45
        for match in re.finditer(r'eGFR\s*(\d+)-(\d+)', text):
            constraints.append({
                'metric': 'eGFR',
                'operator': 'BETWEEN',
                'value_min': float(match.group(1)),
                'value_max': float(match.group(2)),
                'unit': 'mL/min',
                'severity': 'WARNING',
                'context': match.group(0)
            })
        
        # CrClæå–
        for match in re.finditer(r'(CrCl|è‚Œé…æ¸…é™¤ç‡)\s*([<>â‰¥â‰¤ï¼œï¼])\s*(\d+)', text):
            operator = match.group(2).replace('ï¼œ', '<').replace('ï¼', '>')
            value = float(match.group(3))
            
            constraints.append({
                'metric': 'CrCl',
                'operator': operator,
                'value': value,
                'unit': 'mL/min',
                'severity': 'CRITICAL' if operator == '<' and value <= 30 else 'WARNING',
                'context': match.group(0)
            })
        
        # ALT/ASTæå–
        for match in re.finditer(r'(ALT|AST|è½¬æ°¨é…¶)\s*>\s*(\d+)\s*å€', text):
            metric_name = 'ALT' if 'ALT' in match.group(1) else 'AST' if 'AST' in match.group(1) else 'è½¬æ°¨é…¶'
            constraints.append({
                'metric': metric_name,
                'operator': '>',
                'value': float(match.group(2)),
                'unit': 'å€æ­£å¸¸å€¼',
                'severity': 'WARNING',
                'context': match.group(0)
            })
        
        return constraints
    
    def extract_dosage_info(self, text: str) -> Dict:
        """æå–å‰‚é‡ä¿¡æ¯"""
        dosage_info = {}
        
        # æœ€å¤§å‰‚é‡
        max_dose_match = re.search(r'æœ€å¤§å‰‚é‡[ä¸ºï¼š:]*\s*(\d+[.\d]*)\s*(mg|g|Î¼g|å•ä½)', text)
        if max_dose_match:
            dosage_info['max_daily_dose'] = f"{max_dose_match.group(1)}{max_dose_match.group(2)}"
        
        # èµ·å§‹å‰‚é‡
        start_dose_match = re.search(r'èµ·å§‹å‰‚é‡[ä¸ºï¼š:]*\s*(\d+[.\d]*)\s*(mg|g|Î¼g)', text)
        if start_dose_match:
            dosage_info['starting_dose'] = f"{start_dose_match.group(1)}{start_dose_match.group(2)}"
        
        # æœè¯æ—¶é—´
        timing_patterns = [
            r'(é¤å‰|é¤å|éšé¤|ç©ºè…¹|ç¡å‰|æ™¨èµ·)',
            r'(æ—©[é¤æ™¨åˆ]|æ™š[é¤é¥­]|ä¸­åˆ)\s*(å‰|å|æ—¶)',
        ]
        for pattern in timing_patterns:
            timing_match = re.search(pattern, text)
            if timing_match:
                dosage_info['timing'] = timing_match.group(0)
                break
        
        # ç»™è¯é€”å¾„
        if 'æ³¨å°„' in text:
            dosage_info['route'] = 'æ³¨å°„'
        elif 'å£æœ' in text:
            dosage_info['route'] = 'å£æœ'
        elif 'çš®ä¸‹' in text:
            dosage_info['route'] = 'çš®ä¸‹æ³¨å°„'
        
        return dosage_info
    
    def process_drug(self, drug: Dict) -> Dict:
        """å¤„ç†å•ä¸ªè¯å“,æå–æ‰€æœ‰å®ä½“å’Œå…³ç³»"""
        drug_data = {
            'drug': {
                'id': drug['id'],
                'name': drug['name'],
                'en_name': drug.get('en_name', ''),
                'dosage_info': self.extract_dosage_info(drug.get('dosage', '')),
            },
            'category': self.infer_category(drug),
            'brands': drug.get('brand_names', []),
            'treats': [],  # é€‚åº”ç—‡
            'forbidden_diseases': [],  # ç¦å¿Œç–¾ç—…
            'metric_constraints': [],  # Metricçº¦æŸ
        }
        
        # æå–é€‚åº”ç—‡ç–¾ç—…
        if drug.get('indications'):
            drug_data['treats'] = self.extract_diseases(drug['indications'], 'é€‚åº”ç—‡')
        
        # æå–ç¦å¿Œç–¾ç—…å’ŒMetricçº¦æŸ
        if drug.get('contraindications'):
            drug_data['forbidden_diseases'] = self.extract_diseases(drug['contraindications'], 'ç¦å¿Œ')
            drug_data['metric_constraints'] = self.extract_metric_constraints(drug['contraindications'])
        
        # ä»ç”¨æ³•ç”¨é‡ä¸­ä¹Ÿæå–Metricçº¦æŸ
        if drug.get('dosage'):
            dosage_constraints = self.extract_metric_constraints(drug['dosage'])
            drug_data['metric_constraints'].extend(dosage_constraints)
        
        # å»é‡çº¦æŸ
        seen_constraints = set()
        unique_constraints = []
        for c in drug_data['metric_constraints']:
            key = f"{c['metric']}_{c['operator']}_{c.get('value', '')}_{c.get('value_min', '')}"
            if key not in seen_constraints:
                unique_constraints.append(c)
                seen_constraints.add(key)
        drug_data['metric_constraints'] = unique_constraints
        
        return drug_data


def process_all_drugs(input_file: str, output_file: str):
    """å¤„ç†æ‰€æœ‰è¯å“"""
    print("=" * 60)
    print("ğŸ§¬ å®ä½“å’Œå…³ç³»æå–å™¨")
    print("=" * 60)
    
    # è¯»å–ç»“æ„åŒ–æ•°æ®
    print(f"ğŸ“– æ­£åœ¨è¯»å–: {input_file}")
    with open(input_file, 'r', encoding='utf-8') as f:
        drugs = json.load(f)
    
    print(f"ğŸ“Š åŠ è½½äº† {len(drugs)} ä¸ªè¯å“")
    
    # åˆå§‹åŒ–æå–å™¨
    extractor = EntityExtractor()
    
    # å¤„ç†æ¯ä¸ªè¯å“
    graph_data = []
    stats = {
        'categories': defaultdict(int),
        'total_treats': 0,
        'total_forbidden': 0,
        'total_constraints': 0,
        'drugs_with_constraints': 0,
    }
    
    print("\nğŸ” å¼€å§‹æå–å®ä½“å’Œå…³ç³»...")
    for i, drug in enumerate(drugs):
        try:
            drug_graph = extractor.process_drug(drug)
            graph_data.append(drug_graph)
            
            # ç»Ÿè®¡
            stats['categories'][drug_graph['category']] += 1
            stats['total_treats'] += len(drug_graph['treats'])
            stats['total_forbidden'] += len(drug_graph['forbidden_diseases'])
            stats['total_constraints'] += len(drug_graph['metric_constraints'])
            if drug_graph['metric_constraints']:
                stats['drugs_with_constraints'] += 1
            
            print(f"âœ… [{i+1}/{len(drugs)}] {drug['name']}: {drug_graph['category']}, "
                  f"{len(drug_graph['metric_constraints'])} çº¦æŸ")
        except Exception as e:
            print(f"âŒ [{i+1}/{len(drugs)}] {drug.get('name', 'æœªçŸ¥')}: {e}")
    
    # ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {output_file}")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(graph_data, f, ensure_ascii=False, indent=2)
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æå–ç»Ÿè®¡")
    print("=" * 60)
    print(f"æ€»è¯å“æ•°: {len(graph_data)}")
    print(f"å«Metricçº¦æŸçš„è¯å“: {stats['drugs_with_constraints']}")
    print(f"æ€»Metricçº¦æŸæ•°: {stats['total_constraints']}")
    print(f"æ€»é€‚åº”ç—‡å…³ç³»: {stats['total_treats']}")
    print(f"æ€»ç¦å¿Œå…³ç³»: {stats['total_forbidden']}")
    
    print("\nğŸ“Š è¯ç‰©åˆ†ç±»ç»Ÿè®¡:")
    for category, count in sorted(stats['categories'].items(), key=lambda x: -x[1]):
        print(f"  {category}: {count}")
    
    # æ˜¾ç¤ºç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ğŸ“‹ å®ä½“æå–ç¤ºä¾‹(å‰2ä¸ªè¯å“)")
    print("=" * 60)
    for drug_graph in graph_data[:2]:
        print(f"\nğŸ’Š {drug_graph['drug']['name']}")
        print(f"   åˆ†ç±»: {drug_graph['category']}")
        print(f"   å•†å“å: {', '.join(drug_graph['brands']) if drug_graph['brands'] else 'æ— '}")
        print(f"   é€‚åº”ç—‡: {len(drug_graph['treats'])} ä¸ª")
        print(f"   ç¦å¿Œ: {len(drug_graph['forbidden_diseases'])} ä¸ª")
        print(f"   Metricçº¦æŸ: {len(drug_graph['metric_constraints'])} ä¸ª")
        
        if drug_graph['metric_constraints']:
            print("   çº¦æŸè¯¦æƒ…:")
            for c in drug_graph['metric_constraints'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                if 'value' in c:
                    print(f"     - {c['metric']} {c['operator']} {c['value']} {c.get('unit', '')}")
                else:
                    print(f"     - {c['metric']} BETWEEN {c['value_min']}-{c['value_max']} {c.get('unit', '')}")


if __name__ == "__main__":
    process_all_drugs(
        input_file="drugs_structured.json",
        output_file="graph_data.json"
    )
