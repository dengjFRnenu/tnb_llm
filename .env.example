# ============================================
# Dia-Agent 项目配置文件
# 复制此文件为 .env 并修改配置
# ============================================

# ============================================
# 项目基础配置
# ============================================

# 日志级别: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# ============================================
# Neo4j 数据库配置
# ============================================

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123
NEO4J_DATABASE=neo4j

# ============================================
# 大模型配置 (选择其一)
# ============================================

# 提供商: qwen, deepseek, openai, claude, ollama
LLM_PROVIDER=qwen

# 模型名称 (留空使用默认)
LLM_MODEL=

# 生成参数
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=2000

# --- 通义千问 ---
# 申请地址: https://dashscope.console.aliyun.com/
DASHSCOPE_API_KEY=

# --- DeepSeek ---
# 申请地址: https://platform.deepseek.com/
DEEPSEEK_API_KEY=

# --- OpenAI ---
# 申请地址: https://platform.openai.com/
OPENAI_API_KEY=

# --- Claude ---
# 申请地址: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# --- Ollama 本地 (无需密钥) ---
# 安装: curl -fsSL https://ollama.ai/install.sh | sh
# 模型: ollama pull qwen2.5:7b
LLM_BASE_URL=http://localhost:11434/v1

# ============================================
# 嵌入模型配置
# ============================================

EMBEDDING_MODEL=BAAI/bge-m3
EMBEDDING_DEVICE=cuda

# ============================================
# 重排序模型配置
# ============================================

RERANKER_MODEL=BAAI/bge-reranker-v2-m3
RERANKER_DEVICE=cuda

# ============================================
# API 服务配置
# ============================================

API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=false

# ============================================
# HuggingFace 镜像 (国内加速)
# ============================================

# 取消注释以使用镜像
# HF_ENDPOINT=https://hf-mirror.com
